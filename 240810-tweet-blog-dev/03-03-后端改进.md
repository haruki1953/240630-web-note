### 解决帖子图片顺序无法控制的问题
在Post表添加 imagesOrder 字段，保存图片id数组json字符串
```
imagesOrder  String?
```

运行迁移命令以生成和应用迁移：
```
pnpm prisma migrate dev --name add-imagesOrder
`imagesOrder` 是一个可选字段（通过 `?` 标记），所以它不会对现有的数据造成影响，也不需要为现有的记录提供默认值。
为了使其之前数据库中的数据不受影响，前端判断得到的imagesOrder为null时，则以images本身为准
```

修改后端
```
在发送帖子、修改帖子时，保存图片id数组
```


### 状态管理改进
封装defineStoreSystem，更改save方法

### 优化项目结构
将项目业务相关的零散方法放在 `src/utils`，而将为了方便开发的封装放在 `src/helpers`

### 个人信息功能
- 头像
- 名称
- 简介
- 社交媒体
- 关于（markdown）
- 外链（友情链接/联系方式）

都保存存在json里
```
实现头像与其记录，需要当前头像标记，还需要一个数组
avatar avatarArray
avatar为uuid，前端据此在avatarArray中查找。找不到或avatar为null时，显示默认logo

名称，

要实现外链，需要有两个数组：
外链信息 externalLinks ，外链图标 externalIcons
```

后端新增profileSystem
```
类型，校验模型
默认值
```

图片处理
```
确认存储位置，在system/file中添加avatar与iconSystem，实现存储与删除，之后会由profileSystem调用
关于头像与外链图标，完全由前端进行压缩处理，后端不做处理
```

路由、接口新增
- 编写接口文档
- 编写表单校验schema
- 编写路由
- 编写服务函数
- 测试，完善接口文档
```
新增profile路由

profileGetAll 获取全部信息，包括profileStore信息，帖子、图片统计
profileGetData 帖子、图片统计
profileGetStore 获取profileStore信息

profileUpdateNameBio
profileUpdateAboutMd
profileUpdateSocialMedias

profileAddAvatar
profileDeleteAvatarByUuid
profileDeleteAvatarNotUsed
profileUpdateAvatar

profileAddExternalIcon
profileDeleteExternalIconByUuid
profileDeleteExternalIconNotUsed
profileUpdateExternalLinks

```



### hono托管静态文件 
https://stackoverflow.com/questions/77838482/how-to-serve-static-files-in-node-js-using-hono-js

https://hono.dev/docs/getting-started/nodejs#serve-static-files

https://www.npmjs.com/package/@hono/node-server

```
将后端路由路由都加上 /api
后端新建 /static 目录，存放前端
图片等还是存在 /data/public

将静态托管内容写在 src\routers\static.ts
```

配置托管与缓存，hono文档里不是到为什么没有getContent，但是是必要的
```ts
import { serveStatic } from 'hono/serve-static'
import fsp from 'fs/promises'

router.use('*', serveStatic({
  root: './static',
  getContent: async (path, c) => {
    try {
      const content = await fsp.readFile(path)
      return content
    } catch (error) {
      // console.error('Error reading file:', error)
      return null
    }
  },
  onFound: (_path, c) => {
    c.header('Cache-Control', 'public, immutable, max-age=31536000')
  }
}))

// src\index.ts
app.route('/', staticRouter)
```

改进
```ts
router.use('*', serveStatic({
  root: staticConfig.root,
  getContent: async (path, c) => {
    try {
      const content = await fsp.readFile(path)
      return content
    } catch (error) {
      return null
    }
  },
  onFound: (_path, c) => {
    staticConfig.settings.forEach(setting => {
      if (setting.pathReg.test(_path)) {
        setting.headers.forEach(header => {
          c.header(header.name, header.value)
        })
      }
    })
  }
}))
```


### id从数字改为uuid
检查错误
```
配置 package.json
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "lint": "eslint --ext .ts src"
  },
pnpm lint
（pnpm eslint --ext .ts src）

更全面的类型检查应该使用 TypeScript 编译器 `tsc`
tsc --noEmit

在 Vue 项目中，scripts中有"type-check"
pnpm type-check
```

prisma更改
```
id String @id @default(uuid())
注意，相关的关系字段也要修改

数据库名改为
datasource db {
  provider = "sqlite"
  url      = "file:../data/sqlite.db"
}

运行迁移
pnpm prisma migrate dev --name id-change-int-to-string-uuid
打开Prisma Studio内置GUI
pnpm prisma studio
```


后端更改
- type
- schema
- service
- 游标查询，空字符起始（之前是数字0）

前端更改
- type
- api
- store
- service
- data-handle
- 注意有用id当路由的页面

接口文档

### 使json数据版本兼容
当版本更新后，或许会增加数据，此时加载数据就会失败
```ts
  // load data from file
  const load = () => {
    try {
      const dataJson = fs.readFileSync(filePath, 'utf8')
      const dataObj = JSON.parse(dataJson)
      return storeSchema.parse(dataObj)
    } catch (error) {
      const defaultData = storeSchema.parse(storeDefault())
      const data = JSON.stringify(defaultData, null, 2)
      fs.writeFileSync(filePath, data, 'utf8')
      return defaultData
    }
  }
```

可以在解析失败后，让原有数据与默认数据结合，再次解析
```ts
  // load data from file
  const load = () => {
    let dataObj
    try {
      // 尝试从文件中读取数据
      const dataJson = fs.readFileSync(filePath, 'utf8')
      dataObj = JSON.parse(dataJson)
    } catch (error) {
      // 读取失败则使用默认数据
      dataObj = storeDefault()
    }

    let dataParse
    try {
      // 尝试用zod确保数据结构正确
      dataParse = storeSchema.parse(dataObj)
    } catch (error) {
      // 数据结构不正确，尝试将当前数据与默认数据结合
      const dataMerged = { ...storeDefault(), ...dataObj }
      try {
        // 将旧数据与默认数据结合后，进行验证
        dataParse = storeSchema.parse(dataMerged)
      } catch (error) {
        // 数据结合后仍不正确，直接使用默认数据
        dataParse = storeSchema.parse(storeDefault())
      }
    }

    // 数据解析后，始终对其做一次保存
    const dataStr = JSON.stringify(dataParse, null, 2)
    fs.writeFileSync(filePath, dataStr, 'utf8')
    // 返回解析后的数据
    return dataParse
  }
```

但这样还是不完美，如果json中有一个属性是对象或者包含对象的数组，那如果结构变化，对象中的旧数据与新数据就不会兼容

应该递归合并并校验
```ts
/**
 * 深度合并两个对象，并使用 zod 进行验证
 * @param target - 目标对象，将被合并的对象
 * @param source - 源对象，合并到目标对象的对象
 * @param schema - zod 验证 schema
 * @returns 合并并验证后的对象
 *
 * 该函数通过递归的方式深度合并两个对象，并使用 zod schema 对合并后的结果进行验证。
 * 具体步骤如下：
 * 1. 深度克隆目标对象和源对象，确保不修改原始对象。
 * 2. 遍历目标对象的所有键。
 * 3. 对于每个键，获取对应的 zod schema。
 * 4. 检查源对象的值是否为对象（但不是数组），并且目标对象中存在相同的键：
 *    - 如果是，则递归调用 deepMergeParse 进行深度合并。
 *    - 否则，尝试使用 zod schema 对源对象的值进行验证：
 *      - 如果验证通过，则使用源对象的值。
 *      - 如果验证失败，则使用目标对象的值。
 * 5. 返回合并并验证后的对象。
 */
const deepMergeParse = <Schema extends ZodObject<any>>(targetVal: any, sourceVal: any, schema: Schema) => {
  const target = cloneDeep(targetVal)
  const source = cloneDeep(sourceVal)
  const merged: any = {}

  // 遍历目标对象的所有键
  for (const key in target) {
    // 获取当前键的 schema
    const keySchema = schema.shape[key]

    // 检查源对象的值是否为对象（但不是数组），并且目标对象中存在相同的键
    if (target[key] instanceof Object && !Array.isArray(target[key]) && key in source) {
      // 递归合并嵌套对象
      merged[key] = deepMergeParse(target[key], source[key], keySchema as ZodObject<any>)
    } else {
      let parsed
      try {
        parsed = keySchema.parse(source[key])
      } catch (error) {
        parsed = target[key]
      }
      merged[key] = parsed
    }
  }

  return merged
}
```

以后尽管在store（json）添加数据后，也可兼容之前的数据，不会全部重置
```
需要注意一点的是，对于数组。如果要在数组中的对象中添加数据，则应该是可选的
否则验证不通过就会重置为空数组
```

#### 兼容与备份
当初次校验失败时，备份json文件
```
初次校验
- 成功
	使用数据
- 失败
	备份json文件
	尝试兼容数据
	- 成功
		日志：xxx.json文件数据结构错误，修复成功，数据已合并，旧文件另存为 xxx.json
	- 失败
		日志：xxx.json文件数据结构错误，修复失败，数据已重置，旧文件另存为 xxx.json
```


### 日志系统
```
model Log {
  id        String   @id @default(uuid())
  title     String?
  content   String
  type      String
  createdAt DateTime @default(now())
}
```

```
pnpm prisma migrate dev --name add-log-model
```

```
日志分页查询接口
日志清理接口
```

#### 将日志存在单独的数据库中（想法）
log中的数据比较敏感，所以单独存在另一个数据库文件中
```
数据库中的其他表都是没有很敏感的信息的，这样做的好处是，以后如果将数据同步至 github 会更安全
需要注意的是 json 文件除了 profile 之外，都比较敏感
```

这种操作是叫 配置多个数据源，"多模式(multi-schema)"支持，**但是好像不支持sqlite**

那算了，以后如果要同步至github可以再想办法，比如将数据库中所需内容导出至json，还可以多分为几个文件，文本文件也利于git管理


### 密码加密
```
pnpm add bcryptjs
pnpm add -D @types/bcryptjs
```

```ts
import bcrypt from 'bcryptjs'

const saltRounds = 10;
const plainPassword = 'yourPassword';

// 哈希密码（同步）
try {
    const hash = bcrypt.hashSync(plainPassword, saltRounds);
    console.log('Hashed password:', hash);
} catch (err) {
    console.error(err);
}
// 验证密码（同步）
try {
    const isMatch = bcrypt.compareSync(plainPassword, hashedPassword);
    console.log('Password match:', isMatch);
} catch (err) {
    console.error(err);
}

// 哈希密码（异步）
bcrypt.hash(plainPassword, saltRounds)
    .then(hash => {
        console.log('Hashed password:', hash);
    })
    .catch(err => {
        console.error(err);
    });

// 验证密码（异步）
bcrypt.compare(plainPassword, hashedPassword)
    .then(isMatch => {
        console.log('Password match:', isMatch);
    })
    .catch(err => {
        console.error(err);
    });
```

需要处理的地方
```
初始化
密码验证
密码修改
判断密码是否为默认
```

忘记密码处理方法
```
修改 data/admin.json
将 "username" "password" 这两行删除
用户名将被重置为 admin
密码将被重置为 adminadmin
```


### 提供公开接口
```
### 帖子id查询
### 帖子分页查询
### 图片id查询（这个原本的前端也没用，但为了整齐也提供吧）
### 图片分页查询
### 获取全部信息

```